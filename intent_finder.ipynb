{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intent_finder.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"aezs9ImQRmpI","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","import pandas as pd\n","import math, sys\n","from konlpy.tag import Okt\n","\n","class Filter:\n","    def __init__(self):\n","        self.words = set() #어떤 단어들이 있는지. 집합\n","        self.word_dict = {} #이중 dictionary; [카테고리][단어] 가 몇번 사용됬는지. 히스토그램\n","        self.category_dict = {} #[카테고리] 가 몇번 사용됬는지\n","    \n","    ## text를 조사 어미 구두점을 제외한 단어만 list로 반환\n","    def split(self, text):\n","        results = []\n","        twitter = Okt() #형태소 분석기\n","        malist = twitter.pos(text, norm=True, stem=True) #steam True로 text를 분석.\n","        \n","        # 실습 2\n","        # 아래 for 문을 한줄짜리 for 문으로 바꿔보세요 List Comprehension\n","        for word in malist:\n","#            if not word[1] in [\"Josa\", \"Eomi\",\"Punctuation\"]:\n","#                results.append(word[0])\n","            if word[1] in ['Noun','Adjective']:\n","                results.append(word[0])\n","        return results\n","\n","    ## word_dict 히스토램(word_dict)과, word 목록에 추가하는 작업.\n","    def inc_word(self, word, category):\n","        if not category in self.word_dict:\n","            self.word_dict[category] = {}\n","        if not word in self.word_dict[category]:\n","            self.word_dict[category][word] = 0\n","        self.word_dict[category][word] += 1\n","        self.words.add(word)\n","\n","    ## 카테고리 히스토그램 만들기.\n","    def inc_category(self, category):\n","        if not category in self.category_dict:\n","            self.category_dict[category] = 0\n","        self.category_dict[category] += 1\n","\n","    ## 텍스트 넣어서 histogram 만들기\n","    def fit(self, text, category):\n","        word_list = self.split(text) ## 조사 어미 구두점 제외하여 list로 반환\n","        for word in word_list:\n","            self.inc_word(word,category)\n","        self.inc_category(category)\n","    \n","    ## score를 확률적 계산\n","    ## P(카테고리|전체문서) + P( 단어 | 해당카테고리)\n","    def score(self, words, category):\n","        score = math.log(self.category_prob(category)) #해당 카테고리가 나올 확률\n","        for word in words: # 각 단어에 대한 확률의 합.\n","            score += math.log(self.word_prob(word, category))\n","        return score\n","\n","    def predict(self, text):\n","        best_category = None\n","        max_score = -sys.maxsize\n","        words = self.split(text) #형태소 분석 (조사 어미 구두점 빼고 단어 list)\n","        score_list = [] # [(카테고리,score) ...] 쌍으로 들어감. socre_list\n","        for category in self.category_dict.keys():\n","            score = self.score(words, category)\n","            score_list.append((category,score))\n","                        \n","            if score > max_score: #가장 높은 score와 카테고리를 저장.\n","                max_score = score\n","                best_category = category\n","                \n","        return best_category, score_list\n","    \n","    ## 해당 단어가, 카테고리에서 몇번이나 쓰였는지 가져오는 함수.\n","    def get_word_count(self, word, category):\n","        print(self.word_dict.keys())\n","        if word in self.word_dict[category]:\n","            return self.word_dict[category][word]\n","        else:\n","            return 0\n","    \n","    ## 전체 문서수에 대해 해당 카테고리가 몇번이나 나왔는지. 확률. #카테고리가 나올 확률\n","    def category_prob(self, category):\n","        sum_categories = sum(self.category_dict.values()) # 전체 문서의 숫자\n","        category_v = self.category_dict[category] # 해당 카테고리의 숫자\n","        return category_v / sum_categories # 카테고리 수 / 전체 문서의 수\n","    \n","    ## \n","    def word_prob(self, word, category): # \n","        n = self.get_word_count(word, category) + 1 # 해당 단어가 카테고리에서 몇번이나 쓰였는지. log(0)이 없으므로 +1 로 bias\n","        d = sum(self.word_dict[category].values()) + len(self.words) # 해당 카테고리의 단어의 수 + 전체 단어의 수\n","        return n/d\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kekNtvqIR6DB","colab_type":"code","colab":{}},"source":["class Intent_Finder:\n","    def __init__(self):\n","        self.big_filter = Filter()\n","        self.category_filters={}\n","        \n","    def train(self, category, text, data_num):\n","        self.big_filter.fit(text, category)\n","        \n","        if category not in self.category_filters:\n","            self.category_filters[category]= Filter()\n","            \n","        self.category_filters[category].fit(str(text)+str(category),data_num)\n","        \n","    def find_indent(self,text):\n","        best_category,score_list = self.big_filter.predict(text)\n","        score_list.sort(key=lambda x:-x[1])\n","        \n","        return [big_category for big_category,_ in score_list[:3]]\n","        \n","    def find_answer(self,text):\n","        best3_big_categorys = self.find_indent(text)\n","        \n","        answers =[]\n","        for big_category in best3_big_categorys:\n","            _, small_score_list = self.category_filters[big_category].predict(text)\n","            small_score_list.sort(key=lambda x:-x[-1])\n","            answers.extend(small_score_list[:3])\n","        \n","        answers.sort(key=lambda x:-x[1])\n","#        print(answers)\n","        return [num for num, _ in answers]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jaYNT0dRuzm","colab_type":"code","colab":{}},"source":["#%% 0\n","if __name__ ==\"__main__\":\n","    print(__name__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MnFnaK9YRu41","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BEKII77Ru76","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWK79A5DRu-S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}